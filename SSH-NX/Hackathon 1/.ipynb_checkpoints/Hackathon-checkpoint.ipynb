{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96cb07c2-e094-4d6d-b20a-57fc67e1a8b4",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e21ad1-79ff-4ff7-af31-0a8b7afa7d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1980a5a8-2c42-4c1e-9011-4405251545e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/nust61/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ___Cell no. 1___\n",
    "\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import nltk \n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "tokenizer = ToktokTokenizer()\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37784fda-ee69-4fdf-8b5d-527660ba1f2c",
   "metadata": {},
   "source": [
    "# Twitter credentials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32306651-97fd-46e7-aa08-3c9be66e8e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "977d09bc-98c5-44d3-b1f2-baf6cbfeb2a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Authenticating Twitter Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a1c1ac75-bf2c-4e2f-9cb2-e8bd80413077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter_credentials as tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "50e76085-6f50-4cce-93b3-e4964a7debb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(api_key,api_secret_key)\n",
    "auth.set_access_token(access_token,access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "badc31a3-d55c-4a45-bf5d-037350544112",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b613682-638a-41a4-baa5-56ff8afcc9fd",
   "metadata": {},
   "source": [
    "## Collecting Data from Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e994d7-a3c2-4d87-8921-a73da30ea314",
   "metadata": {},
   "source": [
    "#### Building Search Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "71951f7d-db6c-44fc-8119-ba72b0c80091",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Enter your search words in accordance with the basic filtering rules\n",
    "search_words = \"SWAPO OR swapo OR Swapo\"\n",
    "\n",
    "loc= \"-22.967062,18.4929993,1000km\"\n",
    "\n",
    "date_since = \"2019-11-27\"\n",
    "date_until = \"2019-12-31\"\n",
    "\n",
    "# We also want to exclude retweets and replies as this may sway results\n",
    "my_search = search_words + \" -filter:retweets\" + \" -filter:replies\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7b51e654-6ce7-420b-a3e6-1b11fc2dc39f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TweepError",
     "evalue": "[{'message': 'You currently have Essential access which includes access to Twitter API v2 endpoints only. If you need access to this endpoint, you’ll need to apply for Elevated access via the Developer Portal. You can learn more here: https://developer.twitter.com/en/docs/twitter-api/getting-started/about-twitter-api#v2-access-leve', 'code': 453}]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTweepError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [76]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# The Twitter data is stored in a Tweet object which we've called tweets\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tweets \u001b[38;5;241m=\u001b[39m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmy_search\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtweet_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mextended\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeocount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/workshop/lib/python3.8/site-packages/tweepy/binder.py:252\u001b[0m, in \u001b[0;36mbind_api.<locals>._call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m method\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 252\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m     method\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/workshop/lib/python3.8/site-packages/tweepy/binder.py:234\u001b[0m, in \u001b[0;36mbind_api.<locals>.APIMethod.execute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RateLimitError(error_msg, resp)\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TweepError(error_msg, resp, api_code\u001b[38;5;241m=\u001b[39mapi_error_code)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# Parse the response payload\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_cursors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_cursors \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcursor\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mparams\n",
      "\u001b[0;31mTweepError\u001b[0m: [{'message': 'You currently have Essential access which includes access to Twitter API v2 endpoints only. If you need access to this endpoint, you’ll need to apply for Elevated access via the Developer Portal. You can learn more here: https://developer.twitter.com/en/docs/twitter-api/getting-started/about-twitter-api#v2-access-leve', 'code': 453}]"
     ]
    }
   ],
   "source": [
    "\n",
    "# The Twitter data is stored in a Tweet object which we've called tweets\n",
    "tweets = api.search(q=my_search,lang=\"en\",tweet_mode=\"extended\", geocount=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "39008e10-80af-433e-bd0c-1e545d74b40e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [77]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ___Cell no. 7___\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Iterate and print tweets\u001b[39;00m\n\u001b[1;32m      5\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtweets\u001b[49m[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m30\u001b[39m]:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m tweet\u001b[38;5;241m.\u001b[39mfull_text \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m     i \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tweets' is not defined"
     ]
    }
   ],
   "source": [
    "# ___Cell no. 7___\n",
    "\n",
    "\n",
    "# Iterate and print tweets\n",
    "i = 1\n",
    "for tweet in tweets[0:30]:\n",
    "    print(str(i) + ')' + tweet.full_text + '\\n')\n",
    "    i = i + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8ff495ed-420a-45be-b9a0-cd3cfdf59317",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [78]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtweets\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tweets' is not defined"
     ]
    }
   ],
   "source": [
    "print(tweets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6e28b7-5c92-4542-948f-2455089ffb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweepy.Cursor(api.search,\n",
    "                       q=my_search,\n",
    "                       lang=\"en\",\n",
    "                       tweet_mode='extended',\n",
    "                       geocode=loc,\n",
    "                       since=date_since,\n",
    "                       until=date_until,\n",
    "                       result_type=\"recent\").items(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5120b935-0a0f-4090-94d5-47c4097cf6f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tweets' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tweet_info = [[tweet.id_str,tweet.created_at,tweet.user.location,tweet.full_text] for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "afed758c-2d16-4f43-95b2-bd8306829459",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweet_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [80]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Put our data into a dataframe \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39m\u001b[43mtweet_info\u001b[49m, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_id_str\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_time\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_text\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Have a quick look at the dataframe\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tweet_info' is not defined"
     ]
    }
   ],
   "source": [
    "# Put our data into a dataframe \n",
    "df = pd.DataFrame(data=tweet_info, columns=['tweet_id_str','date_time','location','tweet_text'])\n",
    "\n",
    "# Have a quick look at the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "45d0ab69-e2e9-47a7-8b62-e67f0bfbc597",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [81]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ___Cell no. 12___\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,tweet \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m20\u001b[39m)):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, tweet, \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# ___Cell no. 12___\n",
    "\n",
    "for i,tweet in enumerate(df['tweet_text'].head(20)):\n",
    "    print(i+1, tweet, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3301cbed-012b-4df2-8587-834372848ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 13___\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    \"\"\"\n",
    "    A function to clean the tweet text\n",
    "    \"\"\"\n",
    "    #Remove hyper links\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', ' ', text)\n",
    "    \n",
    "    #Remove @mentions\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', ' ', text)\n",
    "    \n",
    "    #Remove anything that isn't a letter, number, or one of the punctuation marks listed\n",
    "    text = re.sub(r\"[^A-Za-z0-9#'?!,.]+\", ' ', text)   \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "90d437ea-b21b-409d-912e-fdddad608f8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [83]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ___Cell no. 14___\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Apply the clean_text function to the 'tweet_text' column\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(clean_text)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# ___Cell no. 14___\n",
    "\n",
    "# Apply the clean_text function to the 'tweet_text' column\n",
    "df['tweet_text']=df['tweet_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0a271856-f8b4-4d17-a1c9-eaaeec2c39c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [84]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ___Cell no. 15___\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,tweet \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m20\u001b[39m)):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, tweet, \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# ___Cell no. 15___\n",
    "\n",
    "for i,tweet in enumerate(df['tweet_text'].head(20)):\n",
    "    print(i+1, tweet, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6df08653-2f13-4f2d-a033-7670a8e4e27d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [85]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ___Cell no. 16___\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m      4\u001b[0m df\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# ___Cell no. 16___\n",
    "\n",
    "df['tweet_text']=df['tweet_text'].str.lower()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ec1478a0-5454-423e-88ea-e4bed3f8ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 17___\n",
    "\n",
    "# Get the list of NLTK stop words\n",
    "\n",
    "stopwords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "facbb9f4-7630-461a-a728-e864f71a67f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ___Cell no. 18___\n",
    "\n",
    "# Let's have a quick look at what words nltk considers to be stop words\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025a53c1-e7f0-47cd-b2b6-7b3e0617014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ___Cell no. 20___\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \n",
    "    \"\"\"\n",
    "    A function to remove stop words\n",
    "    \"\"\"\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    \n",
    "    # Remove stop words\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531745df-2681-40c2-b65d-9828e4445358",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ___Cell no. 21___\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Apply the stopword removal function to the text of all tweets\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(remove_stopwords)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Print the first 20 tweets\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,tweet \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m20\u001b[39m)):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# ___Cell no. 21___\n",
    "\n",
    "# Apply the stopword removal function to the text of all tweets\n",
    "df['tweet_text']=df['tweet_text'].apply(remove_stopwords)\n",
    "\n",
    "# Print the first 20 tweets\n",
    "for i,tweet in enumerate(df['tweet_text'].head(20)):\n",
    "    print(i+1, tweet, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e078daa6-a773-4b7b-93aa-53ef1c699eb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ___Cell no. 22___\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Plot a word cloud\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m all_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin( [data \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet_text\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m      6\u001b[0m word_cloud \u001b[38;5;241m=\u001b[39m WordCloud(width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m21\u001b[39m, max_font_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      7\u001b[0m                        stopwords\u001b[38;5;241m=\u001b[39mstopwords)\u001b[38;5;241m.\u001b[39mgenerate(all_words)\n\u001b[1;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# ___Cell no. 22___\n",
    "\n",
    "# Plot a word cloud\n",
    "\n",
    "all_words = ' '.join( [data for data in df['tweet_text']])\n",
    "word_cloud = WordCloud(width=500, height=400, random_state=21, max_font_size = 100,\n",
    "                       stopwords=stopwords).generate(all_words)\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.imshow(word_cloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9105249f-bde6-49c7-b5a0-344585009591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
